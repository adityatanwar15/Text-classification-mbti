{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npath=\"../input/mbti-type/mbti_1.csv\" #path to data file\ndf = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncnt_srs = df['type'].value_counts()\n\nplt.figure(figsize=(12,4))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Types', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndef load_data(train_data,limit=0, split=0.8):\n    \"\"\"Load data from the IMDB dataset.\"\"\"\n    train_data = train_data[-limit:]\n    Y,X = train_data[\"type\"], train_data[\"posts\"]\n    y = []\n    for y_ in Y:\n        if y_[0] == 'I' : INTROVERTED = True\n        else: INTROVERTED = False\n        if y_[1] == 'N' : INTUTIVE=  True\n        else: INTUTIVE=  False\n        if y_[2] == 'T' : THINKING=  True\n        else: THINKING= False\n        if y_[3] == 'T' : JUGEMENTAL=  True\n        else: JUDGEMENTAL=  False\n        y.append({'INTROVERTED':INTROVERTED,\"INTUTIVE\":INTUTIVE,\"THINKING\":THINKING,\"JUDGEMENTAL\":JUDGEMENTAL})\n            \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n    return (X_train, y_train), (X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom pathlib import Path\nimport thinc.extra.datasets\n\nimport spacy\nfrom spacy.util import minibatch, compounding\n\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(tokenizer, textcat, texts, cats):\n    docs = (tokenizer(text) for text in texts)\n    tp = 1e-8  # True positives\n    fp = 1e-8  # False positives\n    fn = 1e-8  # False negatives\n    tn = 1e-8  # True negatives\n    for i, doc in enumerate(textcat.pipe(docs)):\n        gold = cats[i]\n        for label, score in doc.cats.items():\n            if label not in gold:\n                continue\n            if score >= 0.5 and gold[label] >= 0.5:\n                tp += 1.\n            elif score >= 0.5 and gold[label] < 0.5:\n                fp += 1.\n            elif score < 0.5 and gold[label] < 0.5:\n                tn += 1\n            elif score < 0.5 and gold[label] >= 0.5:\n                fn += 1\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    f_score = 2 * (precision * recall) / (precision + recall)\n    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main(model=None, output_dir=None, n_iter=20, n_texts=2000):\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank('en')  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n    # add the text classifier to the pipeline if it doesn't exist\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if 'textcat' not in nlp.pipe_names:\n        textcat = nlp.create_pipe('textcat')\n        nlp.add_pipe(textcat, last=True)\n    # otherwise, get it, so we can add labels to it\n    else:\n        textcat = nlp.get_pipe('textcat')\n\n    # add label to text classifier\n    textcat.add_label('INTROVERTED')\n    textcat.add_label('INTUTIVE')\n    textcat.add_label('JUDGEMENTAL')\n    textcat.add_label('THINKING')\n\n    # load the IMBD dataset\n    print(\"Loading MBTI data...\")\n    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(df,limit=n_texts)\n    print(\"Using {} examples ({} training, {} evaluation)\"\n          .format(n_texts, len(train_texts), len(dev_texts)))\n    train_data = list(zip(train_texts,\n                          [{'cats': cats} for cats in train_cats]))\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n    with nlp.disable_pipes(*other_pipes):  # only train textcat\n        optimizer = nlp.begin_training()\n        print(\"Training the model...\")\n        print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n        for i in range(n_iter):\n            losses = {}\n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n                           losses=losses)\n            with textcat.model.use_params(optimizer.averages):\n                # evaluate on the dev data split off in load_data()\n                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n            print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n                  .format(losses['textcat'], scores['textcat_p'],\n                          scores['textcat_r'], scores['textcat_f']))\n\n    # test the trained model\n    test_text = \"This movie sucked\"\n    doc = nlp(test_text)\n    print(test_text, doc.cats)\n\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the saved model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        doc2 = nlp2(test_text)\n        print(test_text, doc2.cats)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmain(output_dir=\"./model\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}